## GCD_Course_Project
Course Project for Getting and Cleaning Data

This document will describe the variables, the data, and the transformations performed to clean up the data.

The data used for this project can be downloaded [here] (https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip), and the introduction of the data is [here](http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones).

# The data
The experiments was carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, they captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data.

There are many different kinds of signals were recorded:
```
tBodyAcc-XYZ (Body acceleration along x, y, or z direction)
tGravityAcc-XYZ
tBodyAccJerk-XYZ
tBodyGyro-XYZ
tBodyGyroJerk-XYZ
tBodyAccMag
tGravityAccMag
tBodyAccJerkMag
tBodyGyroMag
tBodyGyroJerkMag
fBodyAcc-XYZ (fast Fourier transform of the body acceleration)
fBodyAccJerk-XYZ
fBodyGyro-XYZ
fBodyAccMag
fBodyAccJerkMag
fBodyGyroMag
fBodyGyroJerkMag
```

And for each signal, several variables were estimated:
```
mean(): Mean value
std(): Standard deviation
mad(): Median absolute deviation 
max(): Largest value in array
min(): Smallest value in array
sma(): Signal magnitude area
energy(): Energy measure. Sum of the squares divided by the number of values. 
iqr(): Interquartile range 
entropy(): Signal entropy
arCoeff(): Autorregresion coefficients with Burg order equal to 4
correlation(): correlation coefficient between two signals
maxInds(): index of the frequency component with largest magnitude
meanFreq(): Weighted average of the frequency components to obtain a mean frequency
skewness(): skewness of the frequency domain signal 
kurtosis(): kurtosis of the frequency domain signal 
bandsEnergy(): Energy of a frequency interval within the 64 bins of the FFT of each window.
angle(): Angle between to vectors.
```

Then the variables were normalized so that they were bounded within -1 and +1. The normalized variables were called the `feature`, and recorded in the data set. Because the features were normalized variables, they are `unit-less`.

There are totally 561 measurements for each activity and each subject. 

For detailed explanation about the experiment and data set, please download the data and refer to the readme file.

# The mission
we were asked to collect, work with, and clean a data set. To be specific:

1. we were asked to combine the training and test sets to create one data set. The one complete data can be generated by the script 'run_analysis.R', with the object name `dat0raw`. The complete data set has dimension of 10299 X 563. 10299 indicates the total number of observation for all subject and all activities. For each observation, there are 563 variables (or features), including the subject ID (Subject.ID), activity types (Activity), and the other 561 variables (or features) described previously.

2. we were asked to extract only the measurements on the mean and standard deviation for each measurement. In order to do so, the key words "mean" and "std" were used for pattern matching. The corresponding measurements were selected to form an new object called `dat0`.

3. we were asked to use descriptive activity names to name the activities in the data set. The original training and test data set had only activity numbers for the 6 different activities. Before combining the two data sets, the activity numbers were replaced by corresponding activities' names.

4. we were asked to appropriately label the data set with descriptive variable names. The original training and test data set had only variables' values, so the feature names from features.txt were added to the combined data set. This was done before generating the object dat0raw.

5. From the data set in step 4, we were asked to create a second, independent tidy data set with the average of each variable for each activity and each subject. This was done by using the `ddply` function from `plyr` package. Basically, the data `dat0` was split by subject IDs and activities, and the mean value for each rest column was calculated by the function `colMeans`. The final data `result` was saved in to a txt file called `GCD_Assignment_Part_5_LG.txt`.